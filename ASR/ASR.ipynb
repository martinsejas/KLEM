{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import librosa.display\n",
    "from itertools import cycle\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "sns.set_theme(style='white', palette=None)\n",
    "color_pal = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all audio data path\n",
    "# The data file path should be like: './Data/user/user.wav'\n",
    "# The label should be like: 'user'\n",
    "\n",
    "audio_files = glob('./Data/*.wav')\n",
    "\n",
    "# Get the labels of each file:\n",
    "labels = []\n",
    "for file in audio_files:\n",
    "    labels.append(file.split('/')[-1][:3]) # suppose we have paths like: './Data/user/user.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate audio sample\n",
    "ipd.Audio(audio_files[0]) # Now there is no file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustration of audio sample in the wave form\n",
    "# When there is/are audio file in the Data, run this code\n",
    "y, sr = librosa.load(audio_files[0])\n",
    "\n",
    "pd.Series(y).plot(figsize=(10, 5),\n",
    "                  lw=1,\n",
    "                  title='Raw Audio Example',\n",
    "                  color=color_pal[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "\n",
    "Transform data into Mel Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = librosa.feature.melspectrogram(y=y, # data to convert to melspectrogram data\n",
    "                                   sr=sr, # sampling rate\n",
    "                                   n_mels=128 * 2)\n",
    "\n",
    "S_db_mel = librosa.amplitude_to_db(S, # Data to get the amplitudes\n",
    "                                   ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrate the Mel Spectrogram\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "img = librosa.display.specshow(S_db_mel, # Data set to draw mel spectogram\n",
    "                               x_axis='time',\n",
    "                               y_axis='log',\n",
    "                               ax=ax)\n",
    "ax.set_title('Mel Spectrogram', fontsize=20)\n",
    "fig.colorbar(img, ax=ax, format=f'%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data to Mel-frequency Cepstral Coefficients data representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = ... # audio_sample.shape[0] // (sr * 3)\n",
    "sliced_audio = ... # sr * 3\n",
    "\n",
    "def slice_audio(audio, partitions=partitions, sliced_audio=sliced_audio):\n",
    "    my_list = [None]*partitions\n",
    "\n",
    "    for i in range(partitions):\n",
    "        my_list[i] = audio[i*slice_audio:(i+1)*slice_audio]\n",
    "    \n",
    "    return np.array(my_list)\n",
    "\n",
    "def mel_freq(data_dir='./Data/'):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_label in os.listdir(data_dir):\n",
    "        class_dir = os.path.join(data_dir, class_label)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for filename in os.listdir(class_dir):\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "                \n",
    "                # Load the audio file\n",
    "                audio, sr = librosa.load(file_path)\n",
    "                partitions = audio.shape[0] // (sr * 3)\n",
    "                slice_audio = sr * 3\n",
    "                \n",
    "                audios = slice_audio(audio,\n",
    "                                     partitions=partitions,\n",
    "                                     sliced_audio=slice_audio)\n",
    "                \n",
    "                for aud in audios:\n",
    "                    # Extract MFCC features\n",
    "                    mfcc = librosa.feature.mfcc(y=aud,\n",
    "                                                sr=sr,\n",
    "                                                n_mfcc=13,\n",
    "                                                hop_length=512,\n",
    "                                                n_mels=26)\n",
    "                    # Append the features and label to the lists\n",
    "                    features.append(mfcc)\n",
    "                    labels.append(class_label)\n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel_data():\n",
    "    features, labels = mel_freq()\n",
    "\n",
    "    num_samples = features.shape[0]\n",
    "    num_mfcc = features[0].shape[0]\n",
    "    num_frames = features[0].shape[1]\n",
    "\n",
    "    features_2d = np.reshape(features, (num_samples, num_frames * num_mfcc))\n",
    "    label_map = {'class0': 0, 'class1': 1, 'class2': 2} # rename the keys\n",
    "    labels = [label_map[x] for x in labels]\n",
    "    \n",
    "    return features_2d, labels\n",
    "\n",
    "features_2d, labels = get_mel_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "from sympy.abc import y\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(features_2d, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest classifer model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=500,\n",
    "                             criterion='log_loss',\n",
    "                             max_depth=4,\n",
    "                             min_samples_split=.2,\n",
    "                             min_samples_leaf=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "rfc.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model performance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = rfc.predict(Xtest)\n",
    "print(classification_report(ytest, y_pred))\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print(accuracy_score(ytest, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
