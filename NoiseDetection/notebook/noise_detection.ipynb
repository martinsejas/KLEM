{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "DATA_PATH_TRAIN = \"C:/Users/KB/OneDrive/Desktop/noisedetection/dataset/train\"\n",
    "DATA_PATH_TEST = \"C:/Users/KB/OneDrive/Desktop/noisedetection/dataset/test\"\n",
    "SAMPLE_RATE = 22050\n",
    "MFCC_COUNT = 13\n",
    "\n",
    "# def extract_mfccs(file_path):\n",
    "#     audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, mono=True)\n",
    "#     mfccs = librosa.feature.mfcc(y=audio, sr=SAMPLE_RATE, n_mfcc=MFCC_COUNT)\n",
    "#     return np.mean(mfccs.T, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_mfccs(file_path):\n",
    "    # Skip non-audio files\n",
    "    if not file_path.endswith(('.wav', '.flac', '.mp3')):\n",
    "        print(f\"Skipping {file_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Loading {file_path}\")\n",
    "    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, mono=True)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=SAMPLE_RATE, n_mfcc=MFCC_COUNT)\n",
    "    return np.mean(mfccs.T, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    mfccs = []\n",
    "    labels = []\n",
    "    for label in [\"clean\", \"noise\"]:\n",
    "        folder_path = os.path.join(data_path, label)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            mfcc = extract_mfccs(file_path)\n",
    "            mfccs.append(mfcc)\n",
    "            labels.append(label)\n",
    "    return np.array(mfccs), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(DATA_PATH_TRAIN)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(100, activation='selu', kernel_initializer=\"lecun_normal\", input_shape=(MFCC_COUNT,)),\n",
    "    Dense(50, activation='selu', kernel_initializer=\"lecun_normal\"),\n",
    "    Dense(3, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32, callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_val_pred = np.argmax(model.predict(X_val), axis=-1)\n",
    "\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "cr = classification_report(y_val, y_val_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(cr)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"Model Accuracy: {:.2f}%\".format(accuracy*100))\n",
    "print(\"Model Loss: {:.2f}\".format(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_audio_class(audio_file_path, model, le):\n",
    "    mfcc = extract_mfccs(audio_file_path)\n",
    "    mfcc = np.expand_dims(mfcc, axis=0)  # because the model expects 2D array\n",
    "    prediction = np.argmax(model.predict(mfcc), axis=-1)\n",
    "    prediction_label = le.inverse_transform(prediction)[0]\n",
    "    return prediction_label\n",
    "\n",
    "audio_file_path = \"C:/Users/KB/OneDrive/Desktop/noisedetection/dataset/test/testaudio (1987).wav\"  # Adjust if necessary\n",
    "prediction = predict_audio_class(audio_file_path, model, le)\n",
    "print(f\"The audio is predicted as: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
